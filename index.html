<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="description" content="Bor-Shiun Wang's homepage">
        <meta name="author" content="Bor-Shiun Wang">

        <title>Bor-Shiun Wang's homepage</title>

        <!-- Google Fonts -->
        <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">
        
        <!-- Vendor CSS Files -->
        <link href="assets/vendor/aos/aos.css" rel="stylesheet">
        <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
        <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
        <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
        <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
        <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">


        <!-- Template Main CSS File -->
        <link href="assets/css/style.css" rel="stylesheet">
    </head>

    <body>
        <!-- ============== .nav-menu ================ -->
        <header id="header" class="d-flex flex-column justify-content-center">
            <nav id="navbar" class="navbar nav-menu">
                <ul>
                    <li><a href="#hero" class="nav-link scrollto active"><i class="bx bx-home"></i> <span>Home</span></a></li>
                    <li><a href="#about" class="nav-link scrollto"><i class="bx bx-user"></i> <span>About</span></a></li>
                    <li><a href="#publication" class="nav-link scrollto"><i class='bx bx-file'></i> <span>Publication</span></a></li>
                    <li><a href="#resume" class="nav-link scrollto"><i class="bx bx-file-blank"></i> <span>Resume</span></a></li>
                    <li><a href="#contact" class="nav-link scrollto"><i class="bx bx-envelope"></i> <span>Contact</span></a></li>
                </ul>
            </nav>
        </header>

        <!-- ======= Hero Section ======= -->
        <section id="hero" class="d-flex flex-column justify-content-center">
            <div class="container" data-aos="zoom-in" data-aos-delay="100">
                <h1>Bor-Shiun Wang</h1>
                <div class="social-links">
                    <!-- <a href="#" class="twitter"><i class="bx bxl-twitter"></i></a> -->
                    <!-- <a href="#" class="facebook"><i class="bx bxl-facebook"></i></a> -->
                    <!-- <a href="#" class="instagram"><i class="bx bxl-instagram"></i></a> -->
                    <a href = "https://scholar.google.com/citations?user=tbM40zwAAAAJ&hl=en"><i class='bx bxl-google-plus'></i></a>
                    <a href = "https://www.linkedin.com/in/bor-shiun-wang-712a65286"><i class='bx bxl-linkedin-square'></i></i></a>
                    <a href = "./docs/Bor Shiun Wang E-CV.pdf"><i class='bx bxs-user-detail'></i></a>
                    <!-- <a href="#" class="google-scholar"><i class="bx bxl-skype"></i></a> -->
                    <!-- <a href="#" class="linkedin"><i class="bx bxl-linkedin"></i></a> -->
                </div>
            </div>
        </section><!-- End Hero -->

        <main id="main">
            <!-- ======= About Section ======= -->
            <section id="about" class="about">
                <div class="container" data-aos="fade-up">
                    <div class="section-title">
                        <h2>About</h2>
                        <p>
                            I'm a Ph.D. student in the Enriched Vision Applications Lab (EVA lab) at <a href = "https://www.nycu.edu.tw/nycu/ch/index">National Yang Ming Chiao Tung University</a>. 
                        </p>
                        <p>
                            I'm now advised by Prof. <a href = "https://walonchiu.github.io/">Wei-Chen Chiu</a> and RS <a href="https://chienyiwang.github.io/">Chien-Yi Wang</a>.
                        </p>
                        <p>
                            My research focuses on explainable AI and is interested in exploring cutting-edge AI technologies and applying explainable AI in various domains.
                        </p>
                        <p>
                            I'm also keen to study the various subfields of AI that are currently trending.
                        </p>
                    </div>


                    <div class="row">
                        <div class="col-lg-4">
                            <img src="assets/img/profile-img.png" class="img-thumbnail rounded-circle shadow-4-strong" alt="">
                        </div>
                        <div class="col-lg-8 pt-4 pt-lg-0 content">
                            <h3>Ph.D. student at National Yang Ming Chiao Tung University</h3>
                            <div class="row">
                                <div class="col-lg-6">
                                    <ul>
                                        <li><i class="bi bi-chevron-right"></i> <strong>Interesting:</strong> <span>Explainable AI, Generative AI</span></li>
                                    </ul>
                                </div>
                                <!-- <div class="col-lg-6">
                                    <ul>
                                        <li><i class="bi bi-chevron-right"></i> <strong>Age:</strong> <span>30</span></li>
                                        <li><i class="bi bi-chevron-right"></i> <strong>Degree:</strong> <span>Master</span></li>
                                        <li><i class="bi bi-chevron-right"></i> <strong>PhEmailone:</strong> <span>email@example.com</span></li>
                                        <li><i class="bi bi-chevron-right"></i> <strong>Freelance:</strong> <span>Available</span></li>
                                    </ul>
                                </div> -->
                            </div>
                            <p>
                            </p>
                        </div>
                    </div>

                </div>
            </section><!-- End About Section -->

            <!-- ======= Publication Section ======= -->
            <section id="publication" class="publication resume">
                <div class="container" data-aos="fade-up">
                    <div class="section-title">
                        <h2>Publication</h2>
                    </div>
        
                    <div class="row">
                        <!-- <div class="col-lg-6"> -->
                        <h3 class="resume-title">Conference</h3>

                        <div class="resume-item">
                            <h4>MCPNet: An Interpretable Classifier via Multi-Level Concept Prototypes</h4>
                            <p><b>Bor-Shiun Wang</b>, Chien-Yi Wang*, Wei-Chen Chiu* (*=equal advising)</p>
                            <h5>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2024</h5>
                            <!-- <a href="https://ieeexplore.ieee.org/document/9897463"><i class='bx bx-file', font-size="100 px"></i></a> -->
                            <button class="btn btn-primary" type="button" data-bs-toggle="collapse" data-bs-target="#MCPNet_abstract" aria-expanded="false" aria-controls="MCPNet_abstract">
                                Abstract
                            </button>
                            <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_MCPNet_An_Interpretable_Classifier_via_Multi-Level_Concept_Prototypes_CVPR_2024_paper.pdf"><i class='bx bx-file', font-size="100 px"></i></a>
                            <a href="https://github.com/NVlabs/MCPNet"><i class='bx bxl-github'></i></a>
                            <a href="https://eddie221.github.io/MCPNet/"><i class='bx bx-home'></i></a>
                            <a href="https://www.youtube.com/watch?v=N87svhqzkN4"><i class='bx bxl-youtube'></i></a>
                            <div class="collapse" id="MCPNet_abstract">
                                <div class="card card-body" style="text-align:justify">
                                    Recent advancements in post-hoc and inherently interpretable methods have markedly enhanced the explanations of black box classifier models. These methods operate either through post-analysis or by integrating concept learning during model training. Although being effective in bridging the semantic gap between a model's latent space and human interpretation, these explanation methods only partially reveal the model's decision-making process. The outcome is typically limited to high-level semantics derived from the last feature map. We argue that the explanations lacking insights into the decision processes at low and mid-level features are neither fully faithful nor useful. Addressing this gap, we introduce the Multi-Level Concept Prototypes Classifier (MCPNet), an inherently interpretable model. MCPNet autonomously learns meaningful concept prototypes across multiple feature map levels using Centered Kernel Alignment (CKA) loss and an energy-based weighted PCA mechanism, and it does so without reliance on predefined concept labels. Further, we propose a novel classifier paradigm that learns and aligns multi-level concept prototype distributions for classification purposes. Our experiments reveal that our proposed MCPNet, while being adaptable to various model architectures, offers comprehensive multi-level explanations with maintaining the classification accuracy. Additionally, its concept distribution-based classification approach shows improved generalization capabilities in few-shot classification scenarios.
                                </div>
                            </div>
                        </div>

                        <div class="resume-item">
                            <h4>PRB-FPN+: Video Analytics for Enforcing Motorcycle Helmet Laws</h4>
                            <p><b>Bor-Shiun Wang*</b>, Ping-Yang Chen*, Yi-Kuan Hsieh, Jun-Wei Hsieh, Ming-Ching Chang, JiaXin He, Shin-You Teng, HaoYuan Yue, Yu-Chee Tseng (*=equal contribution)</p>
                            <h5>IEEE Conference on Computer Vision and Pattern Recognition Workshop (CVPRW) on the AI City Challenge, 2023</h5>
                            <!-- <a href="https://ieeexplore.ieee.org/document/9897463"><i class='bx bx-file', font-size="100 px"></i></a> -->
                            <button class="btn btn-primary" type="button" data-bs-toggle="collapse" data-bs-target="#PRB-FPN_abstract" aria-expanded="false" aria-controls="PRB-FPN_abstract">
                                Abstract
                            </button>
                            <a href="https://openaccess.thecvf.com/content/CVPR2023W/AICity/papers/Wang_PRB-FPN_Video_Analytics_for_Enforcing_Motorcycle_Helmet_Laws_CVPRW_2023_paper.pdf"><i class='bx bx-file', font-size="100 px"></i></a>
                            <div class="collapse" id="PRB-FPN_abstract">
                                <div class="card card-body" style="text-align:justify">
                                    We present a video analytic system for enforcing motorcycle helmet regulation as a participation to the AI City Challenge 2023 Track 5 contest. The advert of powerful object detectors enables real-time localization of the road users and even the ability to determine if a motorcyclist or a rider is wearing a helmet. Ensuring road safety is important, as the helmets can effectively provide protection against severe injuries and fatalities. However, monitoring and enforcing helmet compliance is challenging, given the large number of motorcyclists and limited visual input such as occlusions. To address these challenges, we propose a novel two-step approach. First, we introduce the PRB-FPN+, a state-of-the-art detector that excels in object localization. We also explore the benefits of deep supervision by incorporating auxiliary heads within the network, leading to enhanced performance of our deep learning architectures. Second, we utilize an advanced tracker named SMILEtrack to associate and refine the target tracklets. Comprehensive experimental results demonstrate that the PRB-FPN+ outperforms the state-of-the-art detectors on MS-COCO. Our system achieved a remarkable rank of 8 on the AI City Challenge 2023 Track 5 Public Leaderboard.
                                </div>
                            </div>
                        </div>

                        <div class="resume-item">
                            <h4>COFENet: Co-Feature Neural Network Model for Fine-Grained Image Classification</h4>
                            <p><b>Bor-Shiun Wang</b>, Jun-Wei Hsieh, Yi-Kuan Hsieh, Ping-Yang Chen</p>
                            <h5>IEEE International Conference on Image Processing (ICIP), 2022</h5>
                            <button class="btn btn-primary" type="button" data-bs-toggle="collapse" data-bs-target="#COFENet_abstract" aria-expanded="false" aria-controls="COFENet_abstract">
                                Abstract
                            </button>
                            <a href="https://ieeexplore.ieee.org/document/9897463"><i class='bx bx-file', font-size="100 px"></i></a>
                            <div class="collapse" id="COFENet_abstract">
                                <div class="card card-body" style="text-align:justify">
                                    It is challenging to classify patterns with small inter-class variations but large intra-class variations especially for textured objects with relatively small sizes and blurry boundaries. We propose the Co-Feature Network (COFENet), a novel deep learning network for fine-grained texture-based image classification. State-of-the-art (SoTA) methods on this mostly rely on feature concatenation by merging convolutional features into fully connected layers. Some existing work explored the variation between pair-wise features during learning, they only considered the relations in the feature channels, and did not explore the spatial or structural relations among the image regions where the features are extracted from. We propose to leverage such information among the features and their relative spatial layouts to capture richer pairwise, orientationwise, and distancewise relations among feature channels for end-to-end learning of intra-class and inter-class variations.
                                </div>
                            </div>
                        </div>
                        
                        <div class="resume-item">
                            <h4>Learnable Discrete Wavelet Pooling (LDW-Pooling) for Convolutional Networks</h4>
                            <p><b>Bor-Shiun Wang</b>, Jun-Wei Hsieh, Ping-Yang Chen, Ming-Ching Chang, Lipeng Ke, Siwei Lyu</p>
                            <h5>The British Machine Vision Conference (BMVC), 2021</h5>
                            <button class="btn btn-primary" type="button" data-bs-toggle="collapse" data-bs-target="#LDWPool_abstract" aria-expanded="false" aria-controls="LDWPool_abstract">
                                Abstract
                            </button>
                            <a href="https://bmvc2021-virtualconference.com/conference/papers/paper_1204.html"><i class='bx bx-file'></i></a>
                            <div class="collapse" id="LDWPool_abstract">
                                <div class="card card-body" style="text-align:justify">
                                    Pooling is a simple but important layer in modern deep CNN architectures for feature aggregation and extraction. Typical CNN design focuses on the conv layers and activation functions, while leaving the pooling layers without suitable options. We introduce the Learning Discrete Wavelet Pooling (LDW-Pooling) that can be applied universally to replace standard pooling operations to better extract features with improved accuracy and efficiency. Motivated from the wavelet theory, we adopt the low-pass (L) and high-pass (H) filters horizontally and vertically for pooling on a 2D feature map. Feature signals are decomposed into four (LL, LH, HL, HH) subbands to better retain features and avoid information dropping. The wavelet transform ensures features after pooling can be fully preserved and recovered. We next adopt an energy-based attention learning to fine-select crucial and representative features. LDW-Pooling is effective and efficient when compared with other state-of-the-art pooling techniques such as WaveletPooling and LiftPooling. Extensive experimental validation shows that LDW-Pooling can be applied to a wide range of standard CNN architectures in replacing standard (max, mean, mixed, and stochastic) pooling operations and consistently outperforming them.
                                </div>
                            </div>
                        </div>

                        <!-- </div> -->

                        <!-- <div class="col-lg-6">
                            <h3 class="resume-title">Journal</h3>
                            <div class="resume-item">
                            </div>
                        </div> -->
                    </div>
                </div>
                </section><!-- End Publication Section -->

            <!-- ======= Resume Section ======= -->
            <section id="resume" class="resume">
            <div class="container" data-aos="fade-up">
                <div class="section-title">
                    <h2>Resume</h2>
                </div>

                <div class="row">
                    <div class="col-lg-6">
                        <h3 class="resume-title">Education</h3>
                            <div class="resume-item">
                                <h4>Ph.D. in Institute of Computer Science and Engineering</h4>
                                <h5>2022 - Present</h5>
                                <p><em>National Yang Ming Chiao Tung University</em></p>
                                <p></p>
                            </div>

                            <div class="resume-item">
                                <h4>Master in Institute of Intelligent Systems</h4>
                                <h5>2020 - 2022</h5>
                                <p><em>National Chiao Tung University</em></p>
                                <p></p>
                            </div>

                            <div class="resume-item">
                                <h4>Bachelor of Computer Science and Engineering</h4>
                                <h5>2018 - 2022</h5>
                                <p><em>National Taiwan Ocean University</em></p>
                                <p></p>
                            </div>
                        </div>
                    </div>
                </div>

            </div>
            </section><!-- End Resume Section -->

            <!-- ======= Contact Section ======= -->
            <section id="contact" class="contact">
                <div class="container" data-aos="fade-up">
                    <div class="section-title">
                        <h2>Contact</h2>
                    </div>

                    <div class="row mt-1">
                        <div class="col-lg-4">
                            <div class="info">
                                <div class="email">
                                    <i class="bi bi-envelope"></i>
                                    <h4>Email:</h4>
                                    <p>eddiewang.cs10@nycu.edu.tw</p>
                                    <p>eddie1998221@gmail.com</p>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </section><!-- End Contact Section -->

        </main><!-- End #main -->

        <!-- Vendor JS Files -->
        <!-- <script src="assets/vendor/purecounter/purecounter_vanilla.js"></script> -->
        <script src="assets/vendor/aos/aos.js"></script>
        <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
        <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
        <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>

        <!-- Template Main JS File -->
        <script src="assets/js/main.js"></script>
    </body>

</html>